{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI4pBDCjrzam",
        "outputId": "c9e56ee9-b39f-4c4c-980b-e7f4a312e448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccXs0-ntLvbC",
        "outputId": "04eb3293-3363-4c26-b3c5-dd75b54ec5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: scikit-learn 1.6.0\n",
            "Uninstalling scikit-learn-1.6.0:\n",
            "  Successfully uninstalled scikit-learn-1.6.0\n",
            "Collecting scikit-learn==1.5.2\n",
            "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (3.5.0)\n",
            "Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y scikit-learn\n",
        "!pip install scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zFMFNhGOLwaE",
        "outputId": "ee819b90-8270-4102-f6fb-0c5286ad6294"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.5.2'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Rtqc73sTt0",
        "outputId": "dd8bf113-46f6-4612-8040-0c03d6203e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,199 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,560 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,227 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,527 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,591 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,640 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,518 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,663 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,859 kB]\n",
            "Fetched 28.2 MB in 8s (3,573 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python3.8.20\n",
            "E: Couldn't find any package by glob 'python3.8.20'\n",
            "E: Couldn't find any package by regex 'python3.8.20'\n",
            "E: Unable to locate package python3.8.20-distutils\n",
            "E: Couldn't find any package by glob 'python3.8.20-distutils'\n",
            "E: Couldn't find any package by regex 'python3.8.20-distutils'\n",
            "update-alternatives: error: alternative path /usr/bin/python3.8.20 doesn't exist\n",
            "update-alternatives: error: no alternatives for python3\n",
            "--2025-01-12 11:14:45--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2275758 (2.2M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.17M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-01-12 11:14:45 (28.7 MB/s) - ‘get-pip.py’ saved [2275758/2275758]\n",
            "\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.3.1\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install python3.8.20 python3.8.20-distutils -y\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8.20 1\n",
        "!sudo update-alternatives --config python3\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python3 get-pip.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haYjVlC1xORk"
      },
      "source": [
        "###Import and installing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2C0LQSswGjgF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import xgboost\n",
        "import json\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v9tfsMLIWM1"
      },
      "source": [
        "##Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B00MQt4lz8rM"
      },
      "outputs": [],
      "source": [
        "def target_extract(conn):\n",
        "    \"\"\"\n",
        "    This function return The Target of each Device_ID.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    conn: connection\n",
        "        A connection object to the database.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe of the labels.\n",
        "    \"\"\"\n",
        "    cur = conn.cursor()\n",
        "    sql = '''SELECT DISTINCT Device_ID, Target\n",
        "             FROM data;\n",
        "             '''\n",
        "    cur.execute(sql)\n",
        "    target = pd.DataFrame(cur.fetchall(), columns = ['Device_ID', 'Target'])\n",
        "    target['Target'] = target['Target'].astype('int')\n",
        "    return target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tmZxx2pz7YDH"
      },
      "outputs": [],
      "source": [
        "def rename_and_16_convert(dataset,prefix):\n",
        "    \"\"\"\n",
        "    Processing data to reduce memory and creating unique columns names for features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset: dataframe\n",
        "        A dataframe columns includes Device_ID and features to process.\n",
        "    prefix : str\n",
        "        A string to concatenate to the feature names.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        The processed data inclued Device_ID column.\n",
        "    \"\"\"\n",
        "    col_dataset = list(dataset.drop(['Device_ID'], axis=1).columns)\n",
        "    df_device = dataset['Device_ID']\n",
        "\n",
        "    dataset.loc[:,col_dataset] *=1000\n",
        "    dataset = dataset.loc[:,col_dataset].astype('float16')\n",
        "    dataset = pd.concat([dataset, df_device], axis=1)\n",
        "\n",
        "    new_columns_name = {n: f'{prefix}_{n}'for n in col_dataset}\n",
        "\n",
        "    dataset.rename(columns=new_columns_name, inplace=True)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5eQ9g5-vqp_Z"
      },
      "outputs": [],
      "source": [
        "def relative_domain(conn, device_list):\n",
        "    \"\"\"\n",
        "    Feature engeinering: For each Device_ID calculate the proportions of all the domain_Name he entered.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    conn: connection\n",
        "        A connection object to the database.\n",
        "    device_list : list\n",
        "        A list of Device_IDs to calculate their proportions.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with the proportions for each Device_IDs and Domain_Name.\n",
        "    \"\"\"\n",
        "    list_device_str = ', '.join(map(str, device_list))\n",
        "    cur = conn.cursor()\n",
        "    sql = f'''SELECT DISTINCT\n",
        "                Device_ID,\n",
        "                Domain_Name,\n",
        "                Domain_Name_count*1.0 / SUM(Domain_Name_count) OVER (PARTITION BY Device_ID) AS relative_domain\n",
        "            FROM (\n",
        "              SELECT Device_ID, Domain_Name, COUNT(*) as Domain_Name_count\n",
        "            \t\tFROM data\n",
        "            \t\tWHERE Device_ID IN (''' +list_device_str+''')\n",
        "                    GROUP BY Device_ID, Domain_Name\n",
        "            \t\t) subquery;'''\n",
        "    cur.execute(sql)\n",
        "    df = pd.DataFrame(cur.fetchall(), columns = ['Device_ID','Domain_Name', 'relative_domain'])\n",
        "\n",
        "    df = df.pivot_table(index='Device_ID', columns='Domain_Name', values='relative_domain', fill_value=0)\n",
        "    df['Device_ID'] = df.index\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k62itjGQqANl"
      },
      "outputs": [],
      "source": [
        "def cls_proportion(conn, device_list):\n",
        "    \"\"\"\n",
        "    Feature engeinering: For each Device_ID calculate the proportions of all the domain_cls he entered.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    conn: connection\n",
        "        A connection object to the database.\n",
        "    device_list : list\n",
        "        A list of Device_IDs to calculate their proportions.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with the proportions for each Device_IDs and Domain_cls.\n",
        "    \"\"\"\n",
        "    list_device_str = ', '.join(map(str, device_list))\n",
        "    cur = conn.cursor()\n",
        "    sql = '''SELECT\n",
        "                    Device_ID,\n",
        "                    Domain_cls,\n",
        "                    CAST(count_cls AS REAL) / SUM(count_cls) OVER (PARTITION BY Device_ID) AS proportion\n",
        "                    FROM\n",
        "                    (SELECT Device_ID, Domain_cls , COUNT(*) AS count_cls\n",
        "                    FROM (\n",
        "                        SELECT Device_ID, Domain_cls1 AS Domain_cls FROM data WHERE (Domain_cls1 != 0 AND Device_ID IN (''' +list_device_str+'''))\n",
        "                        UNION ALL\n",
        "                        SELECT Device_ID, Domain_cls2 AS Domain_cls FROM data WHERE (Domain_cls2 != 0 AND Device_ID IN (''' +list_device_str+'''))\n",
        "                        UNION ALL\n",
        "                        SELECT Device_ID, Domain_cls3 AS Domain_cls FROM data WHERE (Domain_cls3 != 0 AND Device_ID IN (''' +list_device_str+'''))\n",
        "                        UNION ALL\n",
        "                        SELECT Device_ID, Domain_cls4 AS Domain_cls FROM data WHERE (Domain_cls4 != 0 AND Device_ID IN (''' +list_device_str+'''))\n",
        "                    ) AS combined\n",
        "                    WHERE Domain_cls!=0\n",
        "                    GROUP BY Device_ID, Domain_cls\n",
        "                    ORDER BY Device_ID, Domain_cls)\n",
        "                    subquery;'''\n",
        "\n",
        "    cur.execute(sql)\n",
        "    df = pd.DataFrame(cur.fetchall(), columns = ['Device_ID','Domain_cls', 'proportion'])\n",
        "\n",
        "    df = df.pivot_table(index='Device_ID', columns='Domain_cls', values='proportion', fill_value=0)\n",
        "    df['Device_ID'] = df.index\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vk0RwARwzPWR"
      },
      "outputs": [],
      "source": [
        "def avg_relative_entrances_device_id(conn, hours_duration, device_list):\n",
        "    \"\"\"\n",
        "    Feature engeinering: for each Device_ID calculation of the proportional hits according to the day's parts.\n",
        "    Calculation of proportional hits: For each Device_ID, sum up the proportional hits for each day's part (calculated each day) and divide them by the number of days (all days of internet usage -queries).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    conn: connection\n",
        "        A connection object to the database.\n",
        "    hours_duration : int\n",
        "        The interval duration of each day's parts in hours (Day division to 24/'hours_duration' parts).\n",
        "    device_list : list\n",
        "        A list of Device_IDs to calculate their proportions.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with the proportional hits for each Device_ID and time_range.\n",
        "    \"\"\"\n",
        "    df_sum_relative = sum_relative_entrances_timerange(conn, hours_duration, device_list)\n",
        "\n",
        "    all_desired_combinations = list(pd.MultiIndex.from_product([df_sum_relative['Device_ID'].unique(), range(int(24/hours_duration))], names=['Device_ID', 'time_range']))\n",
        "    diff_to_add = set(all_desired_combinations).difference(set(df_sum_relative.apply(lambda row: (row['Device_ID'], row['time_range']), axis=1).to_list()))\n",
        "    diff_to_add = [x +(0,) for x in diff_to_add]\n",
        "    diff_to_add_df = pd.DataFrame(diff_to_add, columns = list(df_sum_relative.columns))\n",
        "    df_sum_relative = pd.concat([df_sum_relative,diff_to_add_df], axis=0)\n",
        "    df_sum_relative.reset_index(drop = True, inplace = True)\n",
        "\n",
        "    df_days_count_train = count_day_device_id(conn, device_list)\n",
        "\n",
        "    df = pd.merge(df_sum_relative, df_days_count_train, how ='left', on ='Device_ID')\n",
        "    df['relative_part'] = df['sum_relative_part']/df['day_num']\n",
        "    df.drop(['day_num','sum_relative_part'],axis=1, inplace = True)\n",
        "\n",
        "    df = df.pivot_table(index='Device_ID', columns='time_range', values='relative_part', fill_value=0)\n",
        "    df['Device_ID'] = df.index\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uYb7RRCszWF_"
      },
      "outputs": [],
      "source": [
        "def sum_relative_entrances_timerange(conn, hours_duration, device_list):\n",
        "    \"\"\"\n",
        "    For each Device_ID, sum the proportional hits in each day according to the day's parts.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    conn: connection\n",
        "        A connection object to the database.\n",
        "    hours_duration : int\n",
        "        The interval duration of each day's parts in hours (Day division to 24/'hours_duration' parts).\n",
        "    device_list:  list\n",
        "        A list of Device_IDs to calculate their proportions.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe contains Device_ID, part of the day, and the sum of the proportional hits.\n",
        "    \"\"\"\n",
        "    list_device_str = ', '.join(map(str, device_list))\n",
        "    cur = conn.cursor()\n",
        "    sql = f'''SELECT DISTINCT\n",
        "                        Device_ID,\n",
        "                        time_range,\n",
        "                        SUM (relative_part) OVER (PARTITION BY Device_ID,time_range) AS sum_relative_part\n",
        "                    FROM(\n",
        "\n",
        "                            SELECT distinct\n",
        "                                            Device_ID,\n",
        "                                            date,\n",
        "                                            time_range,\n",
        "                                            CAST(COUNT(*) OVER (PARTITION BY Device_ID,date,time_range) AS REAL) / COUNT(*) OVER (PARTITION BY Device_ID,date) AS relative_part\n",
        "                                        FROM\n",
        "                                                    (SELECT\n",
        "                                                            Device_ID,\n",
        "                                                            Datetime,\n",
        "                                                            strftime('%Y-%m-%d', Datetime) AS date,\n",
        "                                                            (CAST(strftime('%H', Datetime) AS INTEGER) / {hours_duration}) AS time_range\n",
        "                                                        FROM\n",
        "                                                            data\n",
        "                                                        WHERE\n",
        "                                                            Device_ID IN (''' +list_device_str+''')\n",
        "                                                    ) subquery\n",
        "                        ) subquery\n",
        "                        ;'''\n",
        "    cur.execute(sql)\n",
        "    df = pd.DataFrame(cur.fetchall(), columns = ['Device_ID','time_range', 'sum_relative_part'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UK2Nyhuqy_2n"
      },
      "outputs": [],
      "source": [
        "def count_day_device_id(conn, device_list):\n",
        "    \"\"\"\n",
        "    This function counts the days with internet usage(queries) of each Device_ID.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    conn: connection\n",
        "        A connection object to the database.\n",
        "    device_list:  list\n",
        "        A list of Device_IDs to calculate their proportions.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe contains Device_ID and total days.\n",
        "    \"\"\"\n",
        "    list_device_str = ', '.join(map(str, device_list))\n",
        "    cur = conn.cursor()\n",
        "    sql = f'''\n",
        "                SELECT\n",
        "                    Device_ID,\n",
        "                    COUNT(DISTINCT strftime('%Y-%m-%d', Datetime)) AS day_num\n",
        "                FROM\n",
        "                    data\n",
        "                WHERE\n",
        "                    Device_ID IN (''' +list_device_str+''')\n",
        "                GROUP BY\n",
        "                    Device_ID\n",
        "                ;'''\n",
        "    cur.execute(sql)\n",
        "    df = pd.DataFrame(cur.fetchall(), columns = ['Device_ID', 'day_num'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wQdYRA_QeXHq"
      },
      "outputs": [],
      "source": [
        "def corresponding_columns_training_set(df_train_col_list, df):\n",
        "    \"\"\"\n",
        "    This function checks the gaps between the features received as arguments and the data's columns. And changes the columns' data to be the same as those received as arguments.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df_train_col_list: list\n",
        "        List of features from the training set\n",
        "    df:  dataframe\n",
        "        A dataset whose columns will be changed according to df_train_col_list.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with columns compatible with those of the training set.\n",
        "    \"\"\"\n",
        "    del_col = set(list(df.columns)) - set(df_train_col_list)\n",
        "    df.drop(columns = del_col, inplace = True)\n",
        "    diff_col = set(df_train_col_list)-set(list(df.columns))\n",
        "    add_to_test = pd.DataFrame(0, index=np.arange(len(df)), columns=list(diff_col)).astype('float16')\n",
        "    df = pd.concat([df, add_to_test], axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSPAZhL3ooUK"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83lhHry4g_NA"
      },
      "source": [
        "##Download the data and split it into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjt44Hq809iU",
        "outputId": "b2721776-56c3-4fce-c9b4-d599bd3dc56b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZa-8iGphDvH"
      },
      "source": [
        "Select the data for model training.\n",
        "(note that running the notebook on the full dataset will not be possible in a standard collab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEPz7qwGhAp4",
        "outputId": "2578bf29-6bd9-4405-e37b-b631567db132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You selected mini dataset\n"
          ]
        }
      ],
      "source": [
        "dataset = \"mini dataset\" #@param [\"full dataset\", \"mini dataset\"]\n",
        "\n",
        "print('You selected', dataset)\n",
        "if dataset == \"mini dataset\":\n",
        "    !gdown --fuzzy \"https://drive.google.com/file/d/1NdgwhvUGxVxmv14GTEEgfvlzco_N5Ytc/view?usp=sharing\"\n",
        "    !unzip \"/content/mini_training_set.zip\"\n",
        "    conn = sqlite3.connect(\"/content/mini_training_set.db\")\n",
        "else:\n",
        "    !gdown --fuzzy \"https://drive.google.com/file/d/1DdJFPcaOGa3grUdygEti8jaWjrReyeQU/view?usp=sharing\"\n",
        "    !unzip \"/content/training_set.zip\"\n",
        "    conn = sqlite3.connect(\"/content/training_set.db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sgZwLe61Q1ab"
      },
      "outputs": [],
      "source": [
        "#Extract the target variable\n",
        "target_df = target_extract(conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xbAuWDhAQslE"
      },
      "outputs": [],
      "source": [
        "#Getting indexes for a partition that preserves the proportions of the data\n",
        "s = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
        "\n",
        "for train_index, test_index in s.split(target_df.Target.values,target_df.Target.values):\n",
        "    train_target = target_df.iloc[train_index,:]\n",
        "    test_target = target_df.iloc[test_index,:]\n",
        "\n",
        "    train_device = list(train_target.Device_ID)\n",
        "    test_device = list(test_target.Device_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzySypEUIZoU"
      },
      "source": [
        "##Feature engineering:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnn25UclhrgF"
      },
      "source": [
        "Features engineering of 3 types to each Device_ID:\n",
        "1. The proportional part of each Domain_Name.\n",
        "2. The proportional part of each Domain_cls.\n",
        "3. The proportional part of internet usage by time ranges of a day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc000ChocA8u"
      },
      "source": [
        "Select duration of day's bins (hours) for features engineering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z9jappUZcE8t"
      },
      "outputs": [],
      "source": [
        "hours_duration = \"3\" # @param [\"2\", \"3\", \"4\", \"6\", \"8\"]\n",
        "hours_duration = int(hours_duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_3HZrK6WjJ4"
      },
      "source": [
        "###Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aF5kl3zhtRfO"
      },
      "outputs": [],
      "source": [
        "domain_name_feat = relative_domain(conn, train_device)\n",
        "domain_name_feat = rename_and_16_convert(domain_name_feat,'Domain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yUfRDPzkwN6Y"
      },
      "outputs": [],
      "source": [
        "cls_name_feat = cls_proportion(conn, train_device)\n",
        "cls_name_feat = rename_and_16_convert(cls_name_feat,'cls')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KojV0elyaHx"
      },
      "outputs": [],
      "source": [
        "ts_feat = avg_relative_entrances_device_id(conn, hours_duration, train_device)\n",
        "ts_feat = rename_and_16_convert(ts_feat,'ts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrobLCiH1MDt"
      },
      "outputs": [],
      "source": [
        "df_train = pd.merge(domain_name_feat, cls_name_feat, how ='left', on ='Device_ID')\n",
        "df_train = pd.merge(df_train, ts_feat, how ='left', on ='Device_ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gmyF_ZdFcLO9"
      },
      "outputs": [],
      "source": [
        "df_train_columns = list(df_train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVlg8d3vWnq7"
      },
      "source": [
        "###Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7UgZaoguWqJB"
      },
      "outputs": [],
      "source": [
        "domain_name_feat_test = relative_domain(conn, test_device)\n",
        "domain_name_feat_test = rename_and_16_convert(domain_name_feat_test,'Domain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PrSzhLi8WqCH"
      },
      "outputs": [],
      "source": [
        "cls_name_feat_test = cls_proportion(conn, test_device)\n",
        "cls_name_feat_test = rename_and_16_convert(cls_name_feat_test,'cls')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMGFPSsYWp7q"
      },
      "outputs": [],
      "source": [
        "ts_feat_test = avg_relative_entrances_device_id(conn, hours_duration, test_device)\n",
        "ts_feat_test = rename_and_16_convert(ts_feat_test,'ts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5WF8Nxcb8l5"
      },
      "outputs": [],
      "source": [
        "df_test = pd.merge(domain_name_feat_test, cls_name_feat_test, how ='left', on ='Device_ID')\n",
        "df_test = pd.merge(df_test, ts_feat_test, how ='left', on ='Device_ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cbTcRa6hg1sA"
      },
      "outputs": [],
      "source": [
        "df_test = corresponding_columns_training_set(list(df_train.columns), df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE75RAqBOUsc"
      },
      "source": [
        "##Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_81obirYC6e"
      },
      "source": [
        "Sort the datasets and the labels by Device_ID and delete it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XOh_5CmeOfBv"
      },
      "outputs": [],
      "source": [
        "df_train.sort_values(by = [\"Device_ID\"], inplace = True)\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "train_target.sort_values(by = [\"Device_ID\"], inplace = True)\n",
        "train_target.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_train_Device_ID = df_train[\"Device_ID\"]\n",
        "df_train.drop(columns = [\"Device_ID\"], inplace = True)\n",
        "train_target.drop(columns = [\"Device_ID\"], inplace = True)\n",
        "\n",
        "train_target['Target'] = train_target.Target.astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cG9DliGXOjD_"
      },
      "outputs": [],
      "source": [
        "df_test.sort_values(by = [\"Device_ID\"], inplace = True)\n",
        "df_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "test_target.sort_values(by = [\"Device_ID\"], inplace = True)\n",
        "test_target.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df_test_Device_ID = df_test[\"Device_ID\"]\n",
        "df_test.drop(columns = [\"Device_ID\"], inplace = True)\n",
        "test_target.drop(columns = [\"Device_ID\"], inplace = True)\n",
        "\n",
        "test_target['Target'] = test_target.Target.astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfDH7pSzLdLs"
      },
      "source": [
        "##Feature elimination & Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO-bEewSZNIj"
      },
      "source": [
        "Select features by 'RFE' and use the fitted estimator as the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "UTOdnQCjWYyb"
      },
      "outputs": [],
      "source": [
        "xgb_reg = xgboost.XGBRegressor(random_state=0, subsample=0.8, colsample_bytree=0.8, learning_rate= 0.1,\n",
        "                               n_estimators= 150, max_depth=6, objective ='binary:logistic' ,eval_metric =roc_auc_score)\n",
        "selector = RFE(xgb_reg, n_features_to_select=1000, step=20000)\n",
        "selector = selector.fit(df_train, train_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMnW1oOXWYyb",
        "outputId": "a2311e18-4ec8-4f2f-e093-2d673d9f5bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The auc for validation set: 0.762\n"
          ]
        }
      ],
      "source": [
        "best_features = list(df_train.columns[selector.support_])\n",
        "test_prediction = selector.estimator_.predict(df_test[best_features])\n",
        "print(f'The auc for validation set: {round(roc_auc_score(test_target.Target,test_prediction), 3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wo0D1RlMzTN"
      },
      "source": [
        "###Save model & Best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NkrDiq6PNoPp"
      },
      "outputs": [],
      "source": [
        "# Now you can use XGBoost methods like this:\n",
        "selector.estimator_.save_model('/content/XGB_model.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bhY4MVohi8LX"
      },
      "outputs": [],
      "source": [
        "#Save best features\n",
        "with open(\"/content/best_features.json\", \"w\") as fp:\n",
        "    json.dump(best_features, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL8o9FVYO8WL"
      },
      "source": [
        "##Prepare submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCXdvUvlP9rz"
      },
      "source": [
        "Attention!\n",
        "\n",
        "Full submission includes the following files in a zip archive:\n",
        "\n",
        "\n",
        "1.   model.py (must) - contains a class named \"model\". The class must have implementations of \"load\", \"init\" and \"predict\" functions:\n",
        "\n",
        "    *   init - initialization function of the model class.\n",
        "    *   load - a function that loads the model and model weights.\n",
        "    *   predict - a function that receives one Device_ID each time (as a DataFrame) and returns a one value prediction.\n",
        "    *   The file may contain other functions (within the class or outside of it)\n",
        "    *   imports used by the class must be compatible with the permitted python packages.\n",
        "\n",
        "2.   metadata (must)\n",
        "\n",
        "    *   contain the command for running the model file - do not change this file\n",
        "3.  model weights (optional)\n",
        "\n",
        "    *   in this example, we demonstrate how to save a XGBoost regressor weights. however, these can be any kind of weights as long as they are compatible with the model and the permitted python packages.\n",
        "    *   if the model depends on these weights, this file is mandatory.\n",
        "4.  Helper_func.py (optional)\n",
        "    *   This file contains helper functions. The file can have a different name as long as it is compatible with model.py\n",
        "    *   if the model depends on these weights, this file is mandatory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87nX4jZoSzKz"
      },
      "source": [
        "Running the following cells will generate a zip file with a valid submission for the competition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzVenBarWYyc",
        "outputId": "45b0b4c0-8f58-4c9f-e493-9b754496444f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing helper_func.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile helper_func.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def relative_domain(data):\n",
        "    \"\"\"\n",
        "    Feature engeinering: calculate the proportions of all the domain_Name.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: dataframe\n",
        "        Browsing data ('Domain_Name' column) of a single Device_ID.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with the proportions for each Domain_Name.\n",
        "    \"\"\"\n",
        "    df = data['Domain_Name'].value_counts(normalize=True)\n",
        "    df = df.to_frame().T\n",
        "    df.reset_index(inplace = True, drop = True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def cls_proportion(data):\n",
        "    \"\"\"\n",
        "    Feature engeinering: calculate the proportions of all the domain_cls.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: dataframe\n",
        "        Browsing data (domain classes' columns) of a single Device_ID.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with the proportions for each Domain_cls.\n",
        "    \"\"\"\n",
        "    combined_cls = data[['Domain_cls1', 'Domain_cls2', 'Domain_cls3', 'Domain_cls4']].values.flatten()\n",
        "    # Filter out the zeros\n",
        "    combined_cls = combined_cls[combined_cls != 0]\n",
        "    df = pd.Series(combined_cls).value_counts(normalize=True)\n",
        "    df = df.to_frame().T\n",
        "    df.reset_index(inplace = True, drop = True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def avg_relative_entrances_device_id(data, hours_duration):\n",
        "    \"\"\"\n",
        "    Feature engeinering: calculation of the proportional hits according to the day's parts.\n",
        "    Calculation of proportional hits: sum up the proportional hits for each day's part (calculated each day) and divide them by the number of days (all days of internet usage -queries).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: dataframe\n",
        "        Browsing data ('Datetime' column) of a single Device_ID.\n",
        "    hours_duration : int\n",
        "        The interval duration of each day's parts in hours (Day division to 24/'hours_duration' parts).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with the proportional hits for each time_range.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.to_datetime(data['Datetime'])\n",
        "    df = df.to_frame()\n",
        "    df['Datetime'] = df['Datetime'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
        "\n",
        "    part_length = hours_duration\n",
        "    num_parts = 24 // part_length\n",
        "\n",
        "    # Assign part of the day to each timestamp\n",
        "    df['part_of_day'] = df['Datetime'].dt.hour // part_length\n",
        "\n",
        "    # Group by date and part of the day, then calculate proportions\n",
        "    date_groups = df.groupby([df['Datetime'].dt.date, 'part_of_day']).size().unstack(fill_value=0)\n",
        "    date_groups = date_groups.divide(date_groups.sum(axis=1), axis=0)\n",
        "\n",
        "    # Add missing parts of the day\n",
        "    for i in range(num_parts):\n",
        "        if i not in date_groups.columns:\n",
        "            date_groups[i] = 0\n",
        "    date_groups = date_groups.sort_index(axis=1)\n",
        "\n",
        "    average_proportions = date_groups.sum(axis=0)/date_groups.shape[0]\n",
        "    return average_proportions.to_frame().T\n",
        "\n",
        "\n",
        "def corresponding_columns_training_set(df_train_col_list, df):\n",
        "    \"\"\"\n",
        "    This function checks the gaps between the features received as arguments and the data's columns, and changes the columns' data to be the same as those received as arguments.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df_train_col_list: list\n",
        "        List of features from the training set\n",
        "    df:  dataframe\n",
        "        A dataset whose columns will be changed according to df_train_col_list.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        A dataframe with columns compatible with those of the training set.\n",
        "    \"\"\"\n",
        "    del_col = set(list(df.columns)) - set(df_train_col_list)\n",
        "    df.drop(columns = del_col, inplace = True)\n",
        "    diff_col = set(df_train_col_list)-set(list(df.columns))\n",
        "    add_to_test = pd.DataFrame(0, index=np.arange(len(df)), columns=list(diff_col)).astype('float16')\n",
        "    df = pd.concat([df, add_to_test], axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "def rename_and_16_convert(dataset, prefix):\n",
        "    \"\"\"\n",
        "    Processing data to reduce memory and creating unique columns names for features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset: dataframe\n",
        "        A dataframe columns includes Device_ID and features to process.\n",
        "    prefix : str\n",
        "        A string to concatenate to the feature names.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataframe\n",
        "        The processed data inclued Device_ID column.\n",
        "    \"\"\"\n",
        "    col_dataset = list(dataset.columns)\n",
        "    dataset *=1000\n",
        "    dataset = dataset.astype('float16')\n",
        "\n",
        "    new_columns_name = {n: f'{prefix}_{n}'for n in col_dataset}\n",
        "\n",
        "    dataset.rename(columns=new_columns_name, inplace=True)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z73DBH2EWYyc",
        "outputId": "d047644e-ba52-4ebd-ba97-d32c9bf02f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import json\n",
        "import xgboost\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from helper_func import *\n",
        "import os\n",
        "\n",
        "\n",
        "class model:\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Init the model\n",
        "        '''\n",
        "        self.model  = xgboost.XGBRegressor(seed=0, subsample=0.8, colsample_bytree=0.8, learning_rate= 0.1, n_estimators= 150, max_depth=6, objective ='binary:logistic',eval_metric =roc_auc_score )\n",
        "        self.hours_duration = 3\n",
        "        self.best_features = []\n",
        "\n",
        "\n",
        "    def load(self, dir_path):\n",
        "        '''\n",
        "        Edit this function to fit your model.\n",
        "\n",
        "        This function should load the model that you trained on the train set.\n",
        "        :param dir_path: A path for the folder the model is submitted\n",
        "        '''\n",
        "        model_name = 'XGB_model.json'\n",
        "        model_file = os.path.join(dir_path, model_name)\n",
        "        self.model.load_model(model_file)\n",
        "\n",
        "        best_features_name = 'best_features.json'\n",
        "        best_features_file = os.path.join(dir_path, best_features_name)\n",
        "        with open(best_features_file, \"r\") as fp:\n",
        "            self.best_features = json.load(fp)\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Edit this function to fit your model.\n",
        "\n",
        "        This function should provide predictions of labels on (test) data.\n",
        "        Make sure that the predicted values are in the correct format for the scoring\n",
        "        metric.\n",
        "        domain_name_feat_X, cls_name_feat_X, ts_feat_X : our code for add features to the data before prediction.\n",
        "        :param X: is DataFrame with the columns - 'Datetime', 'URL', 'Domain_Name','Domain_cls1', 'Domain_cls2', 'Domain_cls3', 'Domain_cls4'.\n",
        "        :return: a float value of the prediction for class 1.\n",
        "        '''\n",
        "\n",
        "        domain_name_feat_X = relative_domain(X[['Domain_Name']])\n",
        "        domain_name_feat_X = rename_and_16_convert(domain_name_feat_X,'Domain')\n",
        "\n",
        "        cls_name_feat_X = cls_proportion(X[['Domain_cls1', 'Domain_cls2', 'Domain_cls3', 'Domain_cls4']])\n",
        "        cls_name_feat_X = rename_and_16_convert(cls_name_feat_X,'cls')\n",
        "\n",
        "        ts_feat_X = avg_relative_entrances_device_id(X[['Datetime']], self.hours_duration)\n",
        "        ts_feat_X = rename_and_16_convert(ts_feat_X,'ts')\n",
        "\n",
        "        df_X = pd.concat([domain_name_feat_X, cls_name_feat_X, ts_feat_X], axis=1)\n",
        "\n",
        "        df_X = corresponding_columns_training_set(self.best_features, df_X)\n",
        "\n",
        "        y = self.model.predict(df_X[self.best_features])\n",
        "\n",
        "        return y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfyDriQknf4d",
        "outputId": "cce17518-a889-4b8a-976e-7a6285676497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing metadata\n"
          ]
        }
      ],
      "source": [
        "%%writefile metadata\n",
        "command: python3 $program/model.py $input $output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaiHxzFknj7F"
      },
      "source": [
        "zip the files to submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcDV7w0vnn-O",
        "outputId": "b39bd5f7-f1b9-4412-ce2d-3b4b451626c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: model.py (deflated 63%)\n",
            "  adding: helper_func.py (deflated 67%)\n",
            "  adding: metadata (stored 0%)\n",
            "  adding: XGB_model.json (deflated 73%)\n",
            "  adding: best_features.json (deflated 78%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r submission.zip model.py helper_func.py metadata XGB_model.json best_features.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EKT4-SOoLrZ"
      },
      "source": [
        "*You can use this notebook to save your file, download it, and submit it on CodaLab.\n",
        "\n",
        "To download the zip file, use the file manager panel.\n",
        "Use View > Table of contents to show the sidebar then click the Files tab. Right-click the file and select Download."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fta-MI5Do69F"
      },
      "source": [
        "###Example - Prediction with the submitted model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN6D61CMpGVV"
      },
      "source": [
        "In this section, we demonstrate how to predict with the submitted model  on Device_ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5posVLFPpUAg"
      },
      "source": [
        "####Download and read one Device_ID for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I34zkD_iyjhG",
        "outputId": "3c999726-5d67-481d-8dd8-36849547229e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/download.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = bs4.BeautifulSoup(line, features=\"html.parser\")\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1v6ibfs73vzgb07c6YsAe44Mp067SYV_x\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy \"https://drive.google.com/file/d/1v6ibfs73vzgb07c6YsAe44Mp067SYV_x/view?usp=sharing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "yjzXTgWFn_Ji"
      },
      "outputs": [],
      "source": [
        "X = pd.read_csv('/content/demo.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "oo2uU1aOp1RO",
        "outputId": "ae3a263f-e978-494d-f931-97e7f40a992b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 33322,\n  \"fields\": [\n    {\n      \"column\": \"Device_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 69811,\n        \"max\": 69811,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          69811\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 10629,\n        \"samples\": [\n          \"2023-04-28 20:42:46+03:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 658077,\n        \"min\": 3103,\n        \"max\": 2406360,\n        \"num_unique_values\": 1157,\n        \"samples\": [\n          1542212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain_Name\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 765241,\n        \"min\": 2147,\n        \"max\": 2392744,\n        \"num_unique_values\": 288,\n        \"samples\": [\n          1481969\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain_cls1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 242,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain_cls2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 313,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain_cls3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 416,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Domain_cls4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "X"
            },
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/e523c247d1e24a05/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 69811,\n            'f': \"69811\",\n        },\n\"2023-04-23 01:23:57+03:00\",\n{\n            'v': 1404944,\n            'f': \"1404944\",\n        },\n{\n            'v': 2133977,\n            'f': \"2133977\",\n        },\n{\n            'v': 368,\n            'f': \"368\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 69811,\n            'f': \"69811\",\n        },\n\"2023-04-23 01:23:57+03:00\",\n{\n            'v': 408178,\n            'f': \"408178\",\n        },\n{\n            'v': 107342,\n            'f': \"107342\",\n        },\n{\n            'v': 332,\n            'f': \"332\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 69811,\n            'f': \"69811\",\n        },\n\"2023-04-23 01:23:57+03:00\",\n{\n            'v': 173328,\n            'f': \"173328\",\n        },\n{\n            'v': 970134,\n            'f': \"970134\",\n        },\n{\n            'v': 669,\n            'f': \"669\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n{\n            'v': 69811,\n            'f': \"69811\",\n        },\n\"2023-04-23 01:23:57+03:00\",\n{\n            'v': 270087,\n            'f': \"270087\",\n        },\n{\n            'v': 2368671,\n            'f': \"2368671\",\n        },\n{\n            'v': 755,\n            'f': \"755\",\n        },\n{\n            'v': 799,\n            'f': \"799\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 69811,\n            'f': \"69811\",\n        },\n\"2023-04-23 01:24:54+03:00\",\n{\n            'v': 270087,\n            'f': \"270087\",\n        },\n{\n            'v': 2368671,\n            'f': \"2368671\",\n        },\n{\n            'v': 755,\n            'f': \"755\",\n        },\n{\n            'v': 799,\n            'f': \"799\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        },\n{\n            'v': 0,\n            'f': \"0\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"number\", \"Device_ID\"], [\"string\", \"Datetime\"], [\"number\", \"URL\"], [\"number\", \"Domain_Name\"], [\"number\", \"Domain_cls1\"], [\"number\", \"Domain_cls2\"], [\"number\", \"Domain_cls3\"], [\"number\", \"Domain_cls4\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n<div id=\"df-63e92d7c-11fe-4ee3-b312-78efb0482941\">\n  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63e92d7c-11fe-4ee3-b312-78efb0482941')\"\n            title=\"Suggest charts\"\n            style=\"display:none;\">\n    \n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n  </button>\n  \n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n  <script>\n    async function quickchart(key) {\n      const quickchartButtonEl =\n        document.querySelector('#' + key + ' button');\n      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n      quickchartButtonEl.classList.add('colab-df-spinner');\n      try {\n        const charts = await google.colab.kernel.invokeFunction(\n            'suggestCharts', [key], {});\n      } catch (error) {\n        console.error('Error during call to suggestCharts:', error);\n      }\n      quickchartButtonEl.classList.remove('colab-df-spinner');\n      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n    }\n    (() => {\n      let quickchartButtonEl =\n        document.querySelector('#df-63e92d7c-11fe-4ee3-b312-78efb0482941 button');\n      quickchartButtonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n    })();\n  </script>\n</div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    ",
            "text/html": [
              "\n",
              "  <div id=\"df-e53e432a-b8e3-4a9c-9479-353219249ff1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Device_ID</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>URL</th>\n",
              "      <th>Domain_Name</th>\n",
              "      <th>Domain_cls1</th>\n",
              "      <th>Domain_cls2</th>\n",
              "      <th>Domain_cls3</th>\n",
              "      <th>Domain_cls4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69811</td>\n",
              "      <td>2023-04-23 01:23:57+03:00</td>\n",
              "      <td>1404944</td>\n",
              "      <td>2133977</td>\n",
              "      <td>368</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69811</td>\n",
              "      <td>2023-04-23 01:23:57+03:00</td>\n",
              "      <td>408178</td>\n",
              "      <td>107342</td>\n",
              "      <td>332</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69811</td>\n",
              "      <td>2023-04-23 01:23:57+03:00</td>\n",
              "      <td>173328</td>\n",
              "      <td>970134</td>\n",
              "      <td>669</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69811</td>\n",
              "      <td>2023-04-23 01:23:57+03:00</td>\n",
              "      <td>270087</td>\n",
              "      <td>2368671</td>\n",
              "      <td>755</td>\n",
              "      <td>799</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69811</td>\n",
              "      <td>2023-04-23 01:24:54+03:00</td>\n",
              "      <td>270087</td>\n",
              "      <td>2368671</td>\n",
              "      <td>755</td>\n",
              "      <td>799</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e53e432a-b8e3-4a9c-9479-353219249ff1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e53e432a-b8e3-4a9c-9479-353219249ff1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e53e432a-b8e3-4a9c-9479-353219249ff1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2e98ebd-581a-42bc-8eb6-75e13ba8b581\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2e98ebd-581a-42bc-8eb6-75e13ba8b581')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2e98ebd-581a-42bc-8eb6-75e13ba8b581 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Device_ID                   Datetime      URL  Domain_Name  Domain_cls1  \\\n",
              "0      69811  2023-04-23 01:23:57+03:00  1404944      2133977          368   \n",
              "1      69811  2023-04-23 01:23:57+03:00   408178       107342          332   \n",
              "2      69811  2023-04-23 01:23:57+03:00   173328       970134          669   \n",
              "3      69811  2023-04-23 01:23:57+03:00   270087      2368671          755   \n",
              "4      69811  2023-04-23 01:24:54+03:00   270087      2368671          755   \n",
              "\n",
              "   Domain_cls2  Domain_cls3  Domain_cls4  \n",
              "0            0            0            0  \n",
              "1            0            0            0  \n",
              "2            0            0            0  \n",
              "3          799            0            0  \n",
              "4          799            0            0  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOZKNHa9p51f"
      },
      "source": [
        "####Create object model, load and predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj4_tjA_qIKl"
      },
      "source": [
        "!unzip the submission files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlC1RX4VqCMk",
        "outputId": "9a721051-43a3-42d9-8971-1402a607887b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/submission.zip\n",
            "  inflating: model.py                \n",
            "  inflating: helper_func.py          \n",
            " extracting: metadata                \n",
            "  inflating: XGB_model.json          \n",
            "  inflating: best_features.json      \n"
          ]
        }
      ],
      "source": [
        "!unzip -o '/content/submission.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl8N76HrqNn-"
      },
      "source": [
        "Create model object, load and predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJJMCmUgqQU8",
        "outputId": "2035f24d-2843-46ee-87d3-d1e4c46a6d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: 0.006801425013691187\n"
          ]
        }
      ],
      "source": [
        "from model import *\n",
        "M = model()\n",
        "M.load('')\n",
        "Y_test=[]\n",
        "unique_Device_IDs = list(set(X.Device_ID))\n",
        "for id in unique_Device_IDs:\n",
        "    X_test = X.loc[X['Device_ID'] == id]\n",
        "    X_test.drop('Device_ID', axis=1, inplace=True)\n",
        "    Y_test.append(M.predict(X_test))\n",
        "\n",
        "print(f'Prediction: {Y_test[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "QCI1mGEqw_U1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
